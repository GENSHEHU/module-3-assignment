{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN's using pyTorch.\n",
    "\n",
    "\n",
    "\n",
    "Automatically downloading the MNIST dataset to my specified directory.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Generator and Discriminator models, training, visualization and comparision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torchvision matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters and training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100        # Dimension of latent\n",
    "batch_size = 128         # Batch size during training \n",
    "feature_map_size = 28         #feature map size\n",
    "num_epochs = 50        # Number of training epochs\n",
    "learning_rate = 0.0002  # Optimizer learning rate\n",
    "beta1 = 0.5             # hyperparameter for Adam\n",
    "beta2 = 0.999           # hyperparameter for Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for GPU and modifying\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n",
    "\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the transformation pipeline to ensure proper scaling for images\n",
    "transform = transforms.Compose([     \n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5))     #Normalizing the images \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\HP\\OneDrive\\Documents\\GAN's Project\\data\\raw\"\n",
    "dataset = datasets.MNIST(root=data_path, train=True, transform=transform, download=True)\n",
    "#MNIST dataset automatically downloaded from Yann LeCun website to my specified directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "#using torchvision MNIST datatset loader.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(\"generated_images\")\n",
    "\n",
    "#created folder to save generated images from the generator\n",
    "output_dir = \"generated_images\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(tensor, title=None):\n",
    "    grid = utils.make_grid(tensor, normalize=True)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN's Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Model: Generates fake images\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_channels=1):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, 128, kernel_size=7, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, img_channels, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.Tanh()  # Output value using Tanh\n",
    "        )\n",
    "        \n",
    "    def forward(self, z):\n",
    "        z = z.view(z.size(0), z.size(1), 1, 1)\n",
    "        return self.main(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(batch_size, latent_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discriminator Model: Distinguishes between the real and generated images.\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__ (self, img_channels=1, feature_map_size=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, feature_map_size, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(feature_map_size, feature_map_size * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(feature_map_size * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(feature_map_size * 2, feature_map_size * 4, kernel_size=3, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(feature_map_size * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(feature_map_size * 4, 1, kernel_size=5, stride=1, padding=0, bias=False),\n",
    "            nn.Sigmoid()  #Output probablity.\n",
    "        ) \n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate models and move to device\n",
    "latent_dim = 100\n",
    "netGen = Generator(latent_dim=latent_dim, img_channels=1).to(device)\n",
    "netDis = Discriminator(img_channels=1, feature_map_size=64).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Cross Entropy Loss Function and Adam Optimizer\n",
    "criterion = nn.BCELoss()     \n",
    "optimizerGen = optim.Adam(netGen.parameters(), lr=learning_rate, betas=(beta1, beta2))\n",
    "optimizerDis = optim.Adam(netDis.parameters(), lr=learning_rate, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelling for Real and Fake images\n",
    "real_label = 1.0\n",
    "fake_label = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating label tensors\n",
    "real_labels = torch.full((batch_size,), 1.0, dtype=torch.float, device=device)\n",
    "fake_labels = torch.full((batch_size,), 0.0, dtype=torch.float, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting GAN training...\")\n",
    "\n",
    "# Recording Generator and Discriminator Loss\n",
    "Gen_losses = []\n",
    "Dis_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (real_images, _) in enumerate(dataloader):\n",
    "        b_size = real_images.size(0)\n",
    "        real_images = real_images.to(device)\n",
    "        # Creating label tensors using predefined values\n",
    "        real_labels = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        fake_labels = torch.full((b_size,), fake_label, dtype=torch.float, device=device)\n",
    "        \n",
    "        # Discriminator Training\n",
    "        try:\n",
    "            netDis.zero_grad()\n",
    "            # Train with real images\n",
    "            output_real = netDis(real_images).view(-1)\n",
    "            lossD_real = criterion(output_real, real_labels)\n",
    "            lossD_real.backward()\n",
    "            \n",
    "            # Train with fake images\n",
    "            noise = torch.randn(b_size, latent_dim, device=device)\n",
    "            fake_images = netGen(noise)\n",
    "            output_fake = netDis(fake_images.detach()).view(-1)\n",
    "            lossD_fake = criterion(output_fake, fake_labels)\n",
    "            lossD_fake.backward()\n",
    "            \n",
    "            # Combined loss\n",
    "            lossD = lossD_real + lossD_fake\n",
    "            optimizerDis.step()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in discriminator training: {str(e)}\")\n",
    "            continue\n",
    "        \n",
    "        # Generator Training\n",
    "        netGen.zero_grad()\n",
    "        output = netDis(fake_images).view(-1)\n",
    "        lossG = criterion(output, real_labels)\n",
    "        lossG.backward()\n",
    "        optimizerGen.step()\n",
    "\n",
    "        # Recording Values of Loss for both Generator and Discriminator\n",
    "        Gen_losses.append(lossG.item())\n",
    "        Dis_losses.append(lossD.item())\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i}/{len(dataloader)}] - Loss_D: {lossD.item():.4f}, Loss_G: {lossG.item():.4f}\")\n",
    "    \n",
    "    # Saving images generated at the current epoch\n",
    "    with torch.no_grad():\n",
    "        fixed_noise = torch.randn(64, latent_dim, device=device)\n",
    "        fake_imgs_epoch = netGen(fixed_noise).detach().cpu()\n",
    "    grid = utils.make_grid(fake_imgs_epoch, nrow=8, normalize=True)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "    plt.title(f\"Generated Images - Epoch {epoch+1}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"generated_images/epoch_{epoch+1}.png\")\n",
    "    plt.close()\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final Generated Images\n",
    "with torch.no_grad():\n",
    "    final_noise = torch.randn(64, latent_dim, device=device)\n",
    "    final_generated = netGen(final_noise).detach().cpu()\n",
    "grid_generated = utils.make_grid(final_generated[:64], nrow=8, normalize=True)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(np.transpose(grid_generated, (1,2,0)))\n",
    "plt.title(\"Final Generated Images\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Performance Evaluation Plot Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Generator and Discriminator Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(Gen_losses, label=\"Generator Loss\")\n",
    "plt.plot(Dis_losses, label=\"Discriminator Loss\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparision Of Final Generated Images with Real Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show final generated images\n",
    "with torch.no_grad():\n",
    "    final_noise = torch.randn(64, latent_dim, device=device)\n",
    "    final_generated = netGen(final_noise).detach().cpu()\n",
    "show_images(final_generated[:64], \"Final Generated Images\")\n",
    "\n",
    "# Show real images for comparison\n",
    "real_samples, _ = next(iter(dataloader))\n",
    "show_images(real_samples[:64], \"Real MNIST Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Generator Model\n",
    "save_path = \"C:/Users/HP/OneDrive/Documents/GAN's Project/model/model.pth\"\n",
    "# Create parent directory if it does not exist\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "torch.save(netGen.state_dict(), save_path)\n",
    "print(f\"Generator model saved to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
